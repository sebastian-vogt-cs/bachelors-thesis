\section[RQ1]{RQ1 - How do the two fitness functions compare overall regarding the neutrality and ruggedness of the fitness landscape of the Android black-box test generation problem?}\label{sec:rq1}

\subsection{Analysis}

To answer how rugged and neutral the fitness landscape is for each fitness function, the data received (exemplified in table \ref{table:walks}) is split up into a separate table for each fitness function. For both fitness functions, the distribution of each measure in the respective sub-table is then represented in a violin plot \cite{hintze1998violin}. This gives a first idea on how the fitness landscapes compare for the two fitness functions across all objectives.

\subsection{Results}

Performing $20$ random walks on each of our $1300$ branches with both fitness functions resulted in $26000$ measure values for each fitness function and measure.

The violin plots for neutrality distance, neutrality volume and information content can be found in figure \ref{fig:violinNeutralInformation}.
For the neutrality distance measure, the boxplots were hardly visible in the violin plot, which is why we plotted the kernel density plot and the boxplot separately.

For the autocorrelation measure, the violin plots for $k = 1, 2, 3$ can be found in figure \ref{fig:violinAutocorr}.
For higher $k$-values, the distribution did not change in a way that is relevant for the discussion, which is why only these three $k$-values are reported.

The autocorrelation measure is not defined for flat walks, who were exclusively observed for code-based fitness, where out of $26000$ walks, $4851$ were entirely flat.
The ratio of flat to non-flat walks for code-based fitness can be found in a bar plot in figure \ref{fig:violinAutocorr}.

\begin{figure}[h]
	\includegraphics[width = 0.5\textwidth]{../jupyter/out/Neutrality distance.pdf}
	\includegraphics[width = 0.5\textwidth]{../jupyter/out/Neutrality distance2.pdf}
	\includegraphics[width = 0.5\textwidth]{../jupyter/out/Neutrality volume.pdf}
	\includegraphics[width = 0.5\textwidth]{../jupyter/out/Information content.pdf}
	\caption{Distribution of neutrality distance, neutrality volume and information content}\label{fig:violinNeutralInformation}
\end{figure}

\begin{figure}[h]
	\includegraphics[width = 0.5\textwidth]{../jupyter/out/autokorrelationviolinsk=1.pdf}
	\includegraphics[width = 0.5\textwidth]{../jupyter/out/autokorrelationviolinsk=2.pdf}
	\includegraphics[width = 0.5\textwidth]{../jupyter/out/autokorrelationviolinsk=3.pdf}
	\includegraphics[width = 0.5\textwidth]{../jupyter/out/autocorrelation-values_two-binsk=1.pdf}
	\caption{Distribution of autocorrelation}\label{fig:violinAutocorr}
\end{figure}

\subsection{Discussion}

The neutrality distance values for branch distance are much more concentrated close to the value $1$ than the values for code-based fitness, as can be seen in figure \ref{fig:violinNeutralInformation}.
This means that branch distance tends to generate smaller sequences of equal fitness at the beginning of a walk than code-based fitness, suggesting that the fitness landscape of the latter is more neutral than the fitness landscape of the former. 
Additionally, for code-based fitness there is a sizeable set of random walks, which have a neutrality distance at the walk length of 751, which means that they were completely flat.
The ratio of flat walks to non-flat walks for code-based fitness can be observed in the bar plot in figure \ref{fig:violinAutocorr}.
This is again a strong indication that the fitness landscape of the code-based fitness function is more neutral than the fitness landscape of the branch distance function.

Neutrality volume paints a similar picture. For code-based fitness, most runs have a rather low neutrality volume, while for branch distance, the distribution is much more balanced around a higher median.
A lower neutrality volume means that there are less areas of equal fitness in a run, meaning that these areas are bigger (keep in mind that a slope of length $n$ has $n$ areas of equal fitness), suggesting that the plateaus generated by branch distance are often smaller than the plateaus generated by code-based fitness.

Regarding ruggedness, figure \ref{fig:violinNeutralInformation} shows that the fitness landscape of branch distance has a rather high information content (IC).
The distribution of the IC values for code-based fitness consists of two main areas.
The first one is at about the same height as the main peak for branch distance, while the second one is close to zero.
An information content (close to) zero means that the walks were almost entirely made up of slopes or neutral areas. While generally lower ruggedness is seen to have a positive impact on search behaviour, in this case it seems reasonable to suppose that the lower ruggedness found in the fitness landscape of code-based fitness is mainly caused by its higher neutrality and not by smooth gradients in the fitness landscape.
This means that while the code-based fitness function seems to generate a less rugged landscape, this is not expected to positively influence the search behaviour.

Looking at autocorrelation, figure \ref{fig:violinAutocorr} shows that for all $k=1, 2, 3$, the autocorrelation for code-based fitness is lower than for branch distance.
For higher $k$-values, the distribution of the autocorrelation values for code-based fitness get squished around the value $0$.
This suggests that code-based fitness generates a more rugged fitness landscape, which is in deviation to what the information content measure suggests.
The first important point that can help reconcile these two results is that many walks for code-based fitness are not included in the violin plot for autocorrelation because they were completely flat, while they generate an information content of $0$.
Secondly, walks that are almost flat result in both a low autocorrelation and a low information content, which could suffice to fully explain the autocorrelation results.
This again supports the previous argument, stating that the low information content of code-based fitness is due to its high neutrality and not due to smooth gradients.

\begin{mdframed}[style=box, frametitle={Summary RQ1:}]
	The fitness landscape of the code-based fitness function seems to contain many plateaus, while the landscape of the branch distance function seems to do so to a lesser extent. 
\end{mdframed}